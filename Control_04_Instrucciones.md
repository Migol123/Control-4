# ğŸ“ Control NÂ° 4: XAI, SerializaciÃ³n y Deployment

**Curso:** Machine Learning Supervisado - PECD UNI  
**Docente:** Jordan King Rodriguez Mallqui  
**SesiÃ³n:** 04 - De la Caja Negra a la Realidad Productiva  
**Fecha de entrega:** _14/12/2025_  
**Modalidad:** Individual o en parejas

---

## ğŸ¯ Objetivo

Aplicar tÃ©cnicas de **Explainable AI (SHAP)**, **validaciÃ³n cruzada avanzada**, **serializaciÃ³n de modelos** y **deployment** para llevar un modelo de Machine Learning desde el notebook hasta una aplicaciÃ³n funcional.

---

## ğŸ“‹ Instrucciones Generales

### 1. SelecciÃ³n del Dataset

Puedes usar el **mismo dataset de los controles anteriores** o elegir uno nuevo. Se recomienda mantener consistencia para poder comparar el progreso a lo largo del curso.

#### ğŸ”¹ OpciÃ³n A: Datasets Sugeridos

| Dataset | DescripciÃ³n | Por quÃ© es bueno para XAI | Enlace |
|---------|-------------|---------------------------|--------|
| **Credit Risk** | PredicciÃ³n de default | Regulaciones exigen explicabilidad | [Kaggle](https://www.kaggle.com/datasets/laotse/credit-risk-dataset) |
| **Employee Attrition** | PredicciÃ³n de rotaciÃ³n | RRHH necesita entender causas | [Kaggle](https://www.kaggle.com/datasets/pavansubhasht/ibm-hr-analytics-attrition-dataset) |
| **Heart Disease** | DiagnÃ³stico mÃ©dico | MÃ©dicos requieren explicaciÃ³n | [UCI ML Repository](https://archive.ics.uci.edu/ml/datasets/heart+disease) |
| **Telco Churn** | Fuga de clientes | Marketing necesita actionable insights | [Kaggle](https://www.kaggle.com/datasets/blastchar/telco-customer-churn) |
| **Loan Default** | PrÃ©stamos | Compliance bancario | [Kaggle](https://www.kaggle.com/datasets/wordsforthewise/lending-club) |

#### ğŸ”¹ OpciÃ³n B: Dataset Propio

Requisitos:
- Problema de **clasificaciÃ³n binaria** o **regresiÃ³n**
- Disponible en **repositorio pÃºblico**
- Al menos **500 registros** y **5+ features**
- Contexto donde la **explicabilidad sea relevante**

---

## ğŸ“¦ Entregables

### A. Notebook Jupyter Principal

#### **1. IntroducciÃ³n y Contexto** (5 pts)
- DescripciÃ³n del problema
- Â¿Por quÃ© es importante explicar las predicciones en este contexto?
- Stakeholders que consumirÃ¡n las explicaciones

#### **2. ValidaciÃ³n Cruzada Avanzada** (15 pts)

Implementar al menos **2 estrategias de cross-validation**:

| Estrategia | CuÃ¡ndo Usarla |
|------------|---------------|
| `StratifiedKFold` | ClasificaciÃ³n con clases desbalanceadas |
| `TimeSeriesSplit` | Datos con componente temporal |
| `GroupKFold` | MÃºltiples observaciones por entidad |
| `RepeatedStratifiedKFold` | Mayor robustez estadÃ­stica |

Para cada estrategia:
- Justificar por quÃ© es apropiada para tu dataset
- Reportar mÃ©tricas con media Â± desviaciÃ³n estÃ¡ndar
- Comparar resultados entre estrategias

```python
from sklearn.model_selection import StratifiedKFold, cross_val_score

cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
scores = cross_val_score(model, X, y, cv=cv, scoring='roc_auc')
print(f"AUC-ROC: {scores.mean():.4f} Â± {scores.std():.4f}")
```

#### **3. Explainable AI con SHAP** (30 pts)

Implementar un anÃ¡lisis completo de SHAP que incluya:

**3.1 InterpretaciÃ³n Global (15 pts)**
- **Bar Plot:** Importancia promedio de features
- **Beeswarm Plot:** DistribuciÃ³n de impactos por feature
- **Heatmap:** VisualizaciÃ³n matricial de SHAP values

```python
import shap

# Crear explainer (usar TreeExplainer para modelos de Ã¡rboles)
explainer = shap.TreeExplainer(model)
shap_values = explainer(X_test)

# Visualizaciones globales
shap.plots.bar(shap_values)
shap.plots.beeswarm(shap_values)
shap.plots.heatmap(shap_values)
```

**3.2 InterpretaciÃ³n Local (10 pts)**
- **Waterfall Plot:** ExplicaciÃ³n de 2-3 predicciones individuales
- **Decision Plot:** Trayectoria de decisiÃ³n
- Narrativa: "Â¿Por quÃ© este cliente tiene alta/baja probabilidad?"

```python
# ExplicaciÃ³n de una predicciÃ³n especÃ­fica
shap.plots.waterfall(shap_values[0])
shap.plots.decision(explainer.expected_value, shap_values.values[:10])
```

**3.3 AnÃ¡lisis de Dependencias (5 pts)**
- **Scatter Plot:** RelaciÃ³n SHAP vs valor de feature para top 2 variables
- Identificar relaciones no lineales e interacciones

```python
shap.plots.scatter(shap_values[:, "feature_name"])
```

#### **4. SerializaciÃ³n del Modelo** (15 pts)

Implementar al menos **2 mÃ©todos de serializaciÃ³n**:

| MÃ©todo | Formato | Ventaja |
|--------|---------|---------|
| Pickle | `.pkl` | Simple, nativo Python |
| Joblib | `.joblib` | Comprimido, eficiente para arrays |
| LightGBM/XGBoost Native | `.txt` / `.json` | Portable, inspeccionable |
| ONNX | `.onnx` | Cross-platform (bonus) |

Para cada mÃ©todo:
- Guardar modelo entrenado
- Cargar y verificar predicciones
- Comparar tamaÃ±o de archivo

```python
import joblib

# Guardar
joblib.dump(model, 'model.joblib', compress=3)

# Cargar
model_loaded = joblib.load('model.joblib')

# Verificar
assert (model.predict(X_test) == model_loaded.predict(X_test)).all()
```

**Guardar metadatos** en JSON:
```python
import json

metadata = {
    "model_name": "credit_scoring_v1",
    "version": "1.0.0",
    "created_at": "2025-12-07",
    "features": list(X.columns),
    "metrics": {"auc": 0.95, "f1": 0.88},
    "threshold": 0.35
}

with open('model_metadata.json', 'w') as f:
    json.dump(metadata, f, indent=2)
```

#### **5. Conclusiones del AnÃ¡lisis** (5 pts)
- Top 3 variables mÃ¡s importantes y su interpretaciÃ³n
- Insights de negocio derivados de SHAP
- Recomendaciones para stakeholders no tÃ©cnicos

---

### B. AplicaciÃ³n de Deployment (30 pts)

Crear una **aplicaciÃ³n Streamlit** que permita:

#### **5.1 Funcionalidad BÃ¡sica (15 pts)**
- Cargar el modelo serializado
- Inputs para las variables del modelo (sliders, selectbox, etc.)
- Mostrar la predicciÃ³n (probabilidad y clase)

#### **5.2 Explicabilidad Integrada (10 pts)**
- Mostrar explicaciÃ³n SHAP de la predicciÃ³n individual
- VisualizaciÃ³n del waterfall plot o similar
- Texto explicativo para usuarios no tÃ©cnicos

#### **5.3 Interfaz de Usuario (5 pts)**
- TÃ­tulo y descripciÃ³n del problema
- OrganizaciÃ³n clara de secciones
- Indicador visual de riesgo (semÃ¡foro, gauge, etc.)

### Estructura de archivos esperada:

```
entrega/
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ Control04_Apellido_Nombre.ipynb
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ app.py                    # AplicaciÃ³n Streamlit
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ model.joblib          # Modelo serializado
â”‚   â”‚   â””â”€â”€ model_metadata.json   # Metadatos
â”‚   â””â”€â”€ requirements.txt          # Dependencias
â””â”€â”€ README.md                     # Instrucciones de ejecuciÃ³n
```

### CÃ³digo base para la app:

```python
# app.py
import streamlit as st
import joblib
import shap
import pandas as pd

# Cargar modelo
@st.cache_resource
def load_model():
    return joblib.load('models/model.joblib')

model = load_model()

st.title("ğŸ¦ Predictor de Riesgo Crediticio")
st.markdown("Ingrese los datos del cliente para obtener la predicciÃ³n")

# Inputs
col1, col2 = st.columns(2)
with col1:
    edad = st.slider("Edad", 18, 80, 35)
    ingresos = st.number_input("Ingresos Mensuales", 1000, 50000, 5000)
with col2:
    deuda = st.slider("Ratio Deuda/Ingreso", 0.0, 1.0, 0.3)
    historial = st.selectbox("Historial Crediticio", ["Bueno", "Regular", "Malo"])

# PredicciÃ³n
if st.button("ğŸ”® Calcular Riesgo"):
    # Preparar datos
    X_new = pd.DataFrame([[edad, ingresos, deuda, historial]], 
                         columns=['edad', 'ingresos', 'deuda', 'historial'])
    
    # Predecir
    proba = model.predict_proba(X_new)[0][1]
    
    # Mostrar resultado
    st.metric("Probabilidad de Default", f"{proba:.1%}")
    
    if proba > 0.5:
        st.error("âš ï¸ ALTO RIESGO")
    else:
        st.success("âœ… BAJO RIESGO")
```

---

## âš ï¸ Criterios de EvaluaciÃ³n

| Criterio | Puntos | DescripciÃ³n |
|----------|--------|-------------|
| **Reproducibilidad** | 10 | Notebook y app ejecutables |
| **ValidaciÃ³n CV** | 15 | Al menos 2 estrategias correctamente implementadas |
| **SHAP Global** | 15 | Bar, Beeswarm, Heatmap con interpretaciÃ³n |
| **SHAP Local** | 15 | Waterfall, Decision Plot con narrativa |
| **SerializaciÃ³n** | 15 | 2+ mÃ©todos con verificaciÃ³n y metadatos |
| **App Streamlit** | 20 | Funcional con explicabilidad integrada |
| **Conclusiones** | 10 | Insights de negocio claros |
| **TOTAL** | **100** | |

---

## ğŸš« Errores que Penalizan

- âŒ SHAP sin interpretaciÃ³n (solo cÃ³digo, sin anÃ¡lisis) (-15 pts)
- âŒ App que no ejecuta (-20 pts)
- âŒ No guardar metadatos del modelo (-5 pts)
- âŒ Usar solo un mÃ©todo de serializaciÃ³n (-5 pts)
- âŒ ValidaciÃ³n con solo train_test_split (-10 pts)
- âŒ No incluir instrucciones para ejecutar la app (-5 pts)

---

## ğŸ“¤ Formato de Entrega

1. **Archivos:** 
   - `Control04_Apellido_Nombre.ipynb`
   - Carpeta `app/` con la aplicaciÃ³n
   - `README.md` con instrucciones

2. **Plataforma:** [Canvas](https://canvas.instructure.com/courses/12906015)

3. **Formato:** ZIP con toda la estructura de carpetas

### Estructura del README.md:

```markdown
# Control 04 - [Tu Nombre]

## DescripciÃ³n
[Breve descripciÃ³n del proyecto]

## Requisitos
```bash
pip install -r requirements.txt
```

## Ejecutar la aplicaciÃ³n
```bash
cd app
streamlit run app.py
```

## Estructura del proyecto
[Explicar carpetas y archivos]
```

---

## ğŸ’¡ Tips para un Buen Trabajo

1. **SHAP es para explicar, no solo mostrar:** Cada grÃ¡fico debe tener un pÃ¡rrafo de interpretaciÃ³n
2. **La app debe ser usable:** Piensa en un usuario no tÃ©cnico
3. **Metadatos son crÃ­ticos:** En producciÃ³n real, sin metadatos el modelo es inÃºtil
4. **Prueba tu app:** AsegÃºrate de que funcione antes de entregar
5. **README completo:** El evaluador debe poder ejecutar todo sin preguntarte

### CÃ³digo de Referencia: SHAP con LightGBM

```python
import lightgbm as lgb
import shap

# Entrenar modelo
model = lgb.LGBMClassifier(random_state=42)
model.fit(X_train, y_train)

# SHAP TreeExplainer (mÃ¡s rÃ¡pido para modelos de Ã¡rboles)
explainer = shap.TreeExplainer(model)
shap_values = explainer(X_test)

# Para clasificaciÃ³n binaria, usar la clase positiva
# shap_values tiene shape (n_samples, n_features) si es binario
# o lista de arrays si es multiclase
```

---

## ğŸ“š Recursos de Apoyo

### ğŸ“‚ Repositorio del Curso
Todo el material estÃ¡ disponible en:

ğŸ”— **[https://github.com/JordanKingPeru/ml-supervisado-uni](https://github.com/JordanKingPeru/ml-supervisado-uni)**

### ğŸ““ Notebooks de la SesiÃ³n 4
- `01_Advanced_Validation.ipynb` - Estrategias de cross-validation
- `02_Explainable_AI_SHAP.ipynb` - Tutorial completo de SHAP
- `03_Model_Serialization.ipynb` - MÃ©todos de serializaciÃ³n

### ğŸ“‚ Aplicaciones de Ejemplo
- `app/app.py` - AplicaciÃ³n completa de referencia
- `app/app_basic.py` - VersiÃ³n mÃ­nima (~80 lÃ­neas)

### ğŸ”— DocumentaciÃ³n Oficial
- [SHAP Documentation](https://shap.readthedocs.io/)
- [Streamlit Documentation](https://docs.streamlit.io/)
- [Joblib Documentation](https://joblib.readthedocs.io/)
- [Cross-Validation - Scikit-Learn](https://scikit-learn.org/stable/modules/cross_validation.html)

### ğŸ“– Lecturas Recomendadas
- *"Interpretable Machine Learning"* - Christoph Molnar (Gratis online)
- *"A Unified Approach to Interpreting Model Predictions"* - Lundberg & Lee (2017)

---

## â“ Preguntas Frecuentes

**P: Â¿Puedo usar otra librerÃ­a de XAI como LIME?**  
R: SÃ­, pero SHAP debe ser el principal. LIME puede ser complementario (+3 pts bonus).

**P: Â¿QuÃ© hago si SHAP tarda mucho?**  
R: Usa `shap.TreeExplainer` para modelos de Ã¡rboles. Reduce el tamaÃ±o del test set si es necesario.

**P: Â¿Puedo usar Gradio en vez de Streamlit?**  
R: SÃ­, se acepta como alternativa vÃ¡lida.

**P: Â¿Es obligatorio el SHAP en la app?**  
R: SÃ­, al menos un waterfall plot o force plot de la predicciÃ³n individual.

**P: Â¿CÃ³mo subo la app a la nube?**  
R: No es obligatorio, pero si despliegas en Streamlit Cloud, Hugging Face Spaces o Render, ganas bonus (+5 pts).

---

## ğŸ† Bonus Points (+15 pts mÃ¡ximo)

- **+5 pts:** Desplegar la app en la nube (Streamlit Cloud, HuggingFace, etc.)
- **+5 pts:** Implementar ONNX para serializaciÃ³n cross-platform
- **+3 pts:** Incluir LIME ademÃ¡s de SHAP
- **+2 pts:** Implementar logging de predicciones en la app

---

## ğŸ“ Nota Final del Curso

Este es el **Ãºltimo control** del curso de Machine Learning Supervisado. El objetivo es que demuestres dominio del ciclo completo:

```
Datos â†’ Pipeline â†’ Modelo â†’ OptimizaciÃ³n â†’ Explicabilidad â†’ ProducciÃ³n
```

Â¡Muestra todo lo aprendido! ğŸš€

---

Â¡Ã‰xitos! ğŸ‰ğŸ”ğŸ“¦

